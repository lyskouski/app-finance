% Copyright 2023 The terCAD team. All rights reserved.
% Use of this content is governed by a CC BY-NC-ND 4.0 license that can be found in the LICENSE file.

\subsection{Supporting Accessibility}
\markboth{Optimizing}{Supporting Accessibility}

Before delving into Flutter's accessibility capabilities, it's important to understand the importance of accessibility. 
Accessible design involves creating applications that can be used by all individuals, including those with visual, 
auditory, motor, or cognitive impairments. Providing equal access to information and services for all users is an 
ethical and social responsibility. Ensuring that our app is accessible \issue{34}{} broadens its user base to include a 
more diverse audience. Lastly, accessibility is often a legal obligation in many regions.

The \q{Semantics} and \q{Tooltip} widgets are the initial building blocks for enhancing accessibility. They play a 
critical role in assisting screen readers by providing context to users with visual impairments. They can be implemented 
by wrapping a button and duplicating its title as a label (some elements, such as \q{FloatingActionButton}, contain the 
label within a set of properties):

\begin{lstlisting}
// ./lib/widgets/wrapper/elevate_button_widget.dart
class ElevatedButtonWidget extends StatelessWidget {
  Widget build(BuildContext context) {
    final colorScheme = context.colorScheme;
    return Semantics(
      label: text,
      child: SizedBox(
        width: double.infinity,
        child: ElevatedButton(
          style: ButtonStyle(
            shape: MaterialStateProperty.resolveWith((states) => 
                const ContinuousRectangleBorder()),
            // Respond to user actions, such as mouse hover
            backgroundColor: 
              MaterialStateProperty.resolveWith<Color>((states) {
                if (states.contains(MaterialState.hovered)) {
                  return hoveredColor ?? 
                      colorScheme.onSecondaryContainer;
                }
                return backgroundColor ?? colorScheme.secondary;
              },
            )),
          onPressed: onPressed,
          child: Text(
            text,
            style: TextStyle(
            color: textColor ?? colorScheme.inversePrimary,
            shadows: const [],
// ... closing brackets
\end{lstlisting}

\noindent Flutter excels in ensuring the accessibility of widgets, allowing them to seamlessly interact with screen 
readers like TalkBack on Android and VoiceOver on iOS, regardless of its role as a canvas for creating user interfaces. 
In this context, the semantic tree in Flutter closely aligns with the widget tree. Flutter integrates with the 
accessibility APIs of the underlying platforms, enabling effective communication with screen readers. Semantic actions 
act as intermediaries between the operating system's accessibility APIs and semantics nodes. This enables various 
interactions, including tapping, long pressing, scrolling, accessibility focus transitions, and other actions. These 
features ensure an accessible user experience.

To validate that our application complies with semantic assertions and provides the expected accessibility, we can use 
the \q{SemanticsOwner} for testing. This allows us to perform programmatically driven tests on the behavior of the 
application's semantics tree:

\begin{lstlisting}
testWidgets('Test semantics actions', (WidgetTester tester) async {
  await tester.pumpWidget(App());
  final semantics = tester.getSemantics(find.text('Home'));
  final owner = tester.binding.pipelineOwner.semanticsOwner;
  owner.performAction(semantics.id,
      SemanticsAction.didGainAccessibilityFocus);
  owner.performAction(semantics.id, SemanticsAction.tap);
});
testWidgets('Test alternative inputs', (WidgetTester tester) async {
  await tester.pumpWidget(App());
  await tester.sendKeyDownEvent(LogicalKeyboardKey.control);
  await tester.sendKeyEvent(LogicalKeyboardKey.keyN);
  await tester.sendKeyUpEvent(LogicalKeyboardKey.control);
  await tester.pumpAndSettle(const Duration(seconds: 1));
  expect(find.text('Create new Transaction'), findsOneWidget);
});
\end{lstlisting}

\begin{table}[h!]
  \begin{tabular}{ |p{7.8cm}||l|  }
    \hline
    Description & Shortcut\\
    \hline
    Open / Close the Navigation Drawer &  \key{Shift} + \key{Enter} \\
    Navigate Up                        &  \key{up} \\
    Navigate Down                      &  \key{down} \\
    Open Selected                      &  \key{Enter} \\
    Zoom In                            &  \key{Ctrl} + \key{+} \\
    Zoom In (with mouse)               &  \key{Ctrl} + \key{scroll down} \\
    Zoom Out                           &  \key{Ctrl} + \key{-} \\
    Zoom Out (with mouse)              &  \key{Ctrl} + \key{scroll up} \\
    Reset Zoom                         &  \key{Ctrl} + \key{0} \\
    Add new Transaction                &  \key{Ctrl} + \key{N} \\
    \hline
  \end{tabular}
  \caption{Shortcuts in the application} \label{tb:shortcuts}
\end{table}

\noindent Accessibility isn't limited to text interpretation. It extends to effectively managing focus for users 
navigating the app with keyboards or voice commands. Navigation can be enhanced with keyboard shortcuts provided by the 
\q{Listener}-widget. This feature is particularly valuable for users who rely on keyboard navigation, either for 
accessibility or for desktop usage. It adheres to accessibility guidelines and makes our application more inclusive and 
user-friendly:

\begin{lstlisting}
// ./lib/widgets/wrapper/input_controller_wrapper.dart
class InputControllerWrapper extends StatefulWidget {/* ... */}

class InputControllerWrapperState 
    extends State<InputControllerWrapper> {
  @override
  Widget build(BuildContext context) {
    // Obtain the current zoom value from 'AppZoom'-provider
    zoom = Provider.of<AppZoom>(context, listen: false);
    // Wrap the widget with listeners
    return Listener(
      onPointerSignal: _onPointerSignal, // Listen for mouse input
      child: RawKeyboardListener(
        focusNode: focus,
        onKey: _onKeyPressed, // Listen for keyboard input
\end{lstlisting}
